{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation\n",
    "*sources:* `https://www.ibm.com/think/topics/image-segmentation`  \n",
    "\n",
    "\n",
    "image segmentation processes image pixel by pixel. It uses various techniques to classify individual pixels as belonging to a certain class or instance. Deep learning models use NNs for pattern recognition and image segmentation. The ouputs of these models are __segmentation masks__ which represent pixel-by-pixel boundaries/shapes of each class in the image.   \n",
    "\n",
    "There are three types of image segmentation tasks, which relate to two types of classes. The classes are \"things\" and \"stuff\":\n",
    "- \"things\" are classes with specific, individual shapes. They are clearly defined and can be clearly counted. Ex. cars or trees or a person\n",
    "- \"stuff\" are classes that are not clearly formed or shaped, like sky or grass or water. They are not usually clearly defined or easily countable, and individual objects of these classes are not usually distinguishable from each other (think blades of grass)\n",
    "  \n",
    "Types of image seg:\n",
    "1. semantic segmentation\n",
    "treats all pixels as \"stuff\"; doesn't differentiate between \"stuff\" and \"things\". Doesn't distinguish between individual instances of certain classes, just recognizes the presence of a certain class.\n",
    "\n",
    "2. instance segmentation\n",
    "instance is kind of the opposite of semantic; it tries to recognize each individual instance of a certain class as separate objects. It ignores \"stuff\" completely and focuses completely on \"things\".   \n",
    "Instance seg algorithms usually do two-stage or one-shot approaches, where two-stage models are usually region-based CNNs. The CNN is used to generate bounding boxes for each instance, then more refined classification is done within the previously generated bounding box. \n",
    "\n",
    "3. panoptic segmentation\n",
    "panoptic combines a little of both the previous types. Each pixel is given a semantic label and an \"instance ID\", and pixels with same label and ID belong to the same object. IDs for \"stuff\" pixels are ignored.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
