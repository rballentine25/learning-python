{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression\n",
    "regression is the relation between an output variable and the input variable(s). linear regression can be either simple linear regression (1 input var) or multiple linear regression (multiple inputs vars)\n",
    "\n",
    "### simple regression\n",
    "simple regression model will find the best line that can represent the data by adjusting the two constants, where the best fit is the one that shows the least amount fo error in predicting the output for a given input value. \n",
    "<br> error function is the difference between actual and predicted. (actual-predicted)\n",
    "<br> RSS = sum(error^2), summed over each point. \n",
    "<br> MSE = (1/n)*RSS (mean squared error)\n",
    "<br>RMSE = sqrt(MSE)  \n",
    "\n",
    "### other notes\n",
    "R^2 values indicate whether variables are correlated. higher R^2 means correlation is stronger  \n",
    "p-value determines whether R^2 value is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate/multiple regression\n",
    "fitting a plane or some higher dimensional object to data. Extension of linear regression involving mulitple independant variables (features) predicting a single dependant variable (target)\n",
    "\n",
    "<br> mathematically, Y = b0 + b1x1 + b2x2 + ... + bnxn\n",
    "\n",
    "steps:\n",
    "* select the most important independant variables (which variables does the dependant variable depend onthe most)\n",
    "* normalize the features by scaling into same range\n",
    "* select hypothesis and cost (error) functions\n",
    "* minimize error (cost function) by adjsuting hypothesis parameters\n",
    "* test hypothesis \n",
    "\n",
    "### hypothesis test for predictors\n",
    "how do we know whether one of the predictors is useful in predicting output?\n",
    "<br> use hypothesis test with null hypothesis and alternative hypothesis. null hypothesis is usually that all coefficients are zero. alternative hypothesis is that at least one coeff is NOT zero. hypothesis test is done using F-statistic, which includes RSS and TSS (ordinary least squares OLS). note that F-stat is not suitable when num of predictors is laege, or when p > n\n",
    "\n",
    "### feature selection\n",
    "two most popular methods are:\n",
    "* forward selection: perform simple linear regression for each predictor to find lowest RSS. add another variable to it and check for best 2 var combo by calculating lowest RSS. continuing adding variables until some stop condntion is statisfied\n",
    "* backward selection: start with all vars, and remove the ar that is least statistically significant (reatest p-valuE). stop when stoping condition is reached, like when there is no more improvement in model score\n",
    "\n",
    "RSS and R^2 used to evaluate model after adding/subtracting a feature. \n",
    "<br>\n",
    "calculate R^2 (coeff of determination), R^2 = 1 - (RSS/TSS) where RSS is sum of squares of residuals and TSS is total sum of squares. remember that R^2 is from 0 to 1, where 1 means model perfectly explains variablility of the dependant variable, and 0 means model does not explain any variability. \n",
    "<br> for multiple regression, R^2 must be adjusted to compensate for additional parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression\n",
    "logistic regression is one of the techniques commonly used in machine learning. it is used for classification tasks, where there are generally a certain number of finite outcomes. logistic regression predicts things that are discrete (true or false) rather than things that are continuous.\n",
    "  \n",
    "logistic regression uses the logit function, which uses the sigmoid function S(x) = 1/(1+e^(-x)) as its \"activiation\" function. sigmoid function returns a number 0-1, on a S-curve. the logistic regression equation is y = e^(b0 + b1x)/(1+b^(b0+b1x)). the sigmoid function tells the probability that a point is true or false (or one or the other), which is used to make a classification.  \n",
    "  \n",
    "logistic regression can be classified into 3 types:  \n",
    "1. binomial: there are only 2 types of dependant variables, which is determined by rounding the sigmoud function to 0 or 1.\n",
    "2. multinomial: two or more discrete outcomes\n",
    "3. ordinal: applies when dependent variable is in an ordered state, where there are 3 or more outcomes\n",
    "\n",
    "logistic regression can work with discrete or continueous data for its features. tests can be run to see if a variable's effect on prediction is significantly different from zero.  \n",
    "\n",
    "logistical regression uses maximum liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
